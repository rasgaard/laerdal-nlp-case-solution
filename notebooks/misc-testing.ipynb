{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "chat = ChatOllama(model=\"llama2:7b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='[IMGREQ]')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\" Answer ONLY the parsable token that is specified in the prompt.\n",
    "        If the user DOES NOT request an image you should respond with a message that says \"[NOREQ]\". \n",
    "        If the user DOES request to see an image you should answer [IMGREQ].\n",
    "\n",
    "        Here are some example requests:\n",
    "        \"Can you show me a cat?\"\n",
    "        \"Find me an image of a bicycle.\"\n",
    "        \"I'd like to see a picture of a mountain.\"\n",
    "        \"I want to see a photo of a dog.\"\n",
    "        \"Find a picture of a woman riding a bike.\"\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Can you show me something cool?\"),\n",
    "]\n",
    "\n",
    "chat(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Thank you for providing me with the image details! Based on your description, I can tell that the image depicts a male individual riding a bicycle while traveling in the same direction as a car. The man is wearing a casual outfit and a helmet, and he appears to be enjoying the ride. The car in the background is also moving forward, but it is not the main focus of the image.\\n\\nI hope this description helps! Is there anything else you would like me to mention about the image?')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"Your job is to describe the image in a way that is useful to the user.\n",
    "        The image will be described to you and you will need to describe it back to the user.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"This image depicts a man riding a bike past a car. and is described as a positive image\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "chat(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"monkey dancing\"')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\" From a user's request, you should translate the request into a search query for an image.\n",
    "\n",
    "        Here are some example requests:\n",
    "        \"Can you show me a cat?\" -> \"cat\"\n",
    "        \"Find me an image of a bicycle.\" -> \"bicycle\"\n",
    "        \"I'd like to see a picture of a mountain.\" -> \"mountain\"\n",
    "        \"I want to see a photo of a woman riding a bike\" -> \"woman riding bike\"\n",
    "        \"Get a picture of a banana split\" -> \"banana split\"\n",
    "\n",
    "        Answer ONLY with the search query.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Show me a dancing monkey\"),\n",
    "]\n",
    "\n",
    "chat(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentiment_file = \"../img_data/coco_ann2014/annotations/with_sentiment.csv\"\n",
    "\n",
    "sentiment_df = pd.read_csv(sentiment_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df[\"sentiment_label_text\"] = sentiment_df.apply(\n",
    "    lambda x: \"Positive\" if x[\"sentiment_label\"] else \"Negative\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(row):\n",
    "    return f\"This image depicts {row['caption'].lower()} and is described as a {row['sentiment_label_text'].lower()} image.\"\n",
    "\n",
    "\n",
    "sentiment_df[\"description\"] = sentiment_df.apply(combine_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.sort_values(by=\"image_id\").reset_index()[\n",
    "    [\"image_id\", \"description\"]\n",
    "].to_csv(\"image_descriptions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"image_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28393494a7c843f2bf1ef09282d4592b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(df[\"description\"].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings to a numpy file\n",
    "import numpy as np\n",
    "\n",
    "np.save(\"image_descriptions.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Get me a picture of a happy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_emb = model.encode(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88323"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([cosine_similarity(msg_emb, emb) for emb in embeddings]).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253386"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[88323][\"image_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "current_dir = os.path.dirname(os.path.realpath(\"./\"))\n",
    "senticap_data_dir = os.path.join(current_dir, \"txt_data\", \"data\")\n",
    "coco_img_data_dir = os.path.join(current_dir, \"img_data\", \"coco_val2014\", \"val2014\")\n",
    "senticap_data_json_path = os.path.join(senticap_data_dir, \"senticap_dataset.json\")\n",
    "senticap_data_csv_path = os.path.join(senticap_data_dir, \"senticap_dataset.csv\")\n",
    "coco_ann_data_dir = os.path.join(current_dir, \"img_data\", \"coco_ann2014\", \"annotations\")\n",
    "coco_cap_data_path = os.path.join(coco_ann_data_dir, \"captions_val2014.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the captions from the coco dataset\n",
    "with open(coco_cap_data_path, \"r\") as f:\n",
    "    coco_cap_data = json.load(f)\n",
    "\n",
    "coco_cap_data_ann = coco_cap_data[\"annotations\"]\n",
    "coco_cap_data_img = coco_cap_data[\"images\"]\n",
    "\n",
    "# Create a dataframe from the coco captions\n",
    "coco_cap_ann_df = pd.DataFrame(coco_cap_data_ann)\n",
    "coco_cap_img_df = pd.DataFrame(coco_cap_data_img)\n",
    "\n",
    "# Rename the id column to image_id\n",
    "coco_cap_img_df.rename(columns={\"id\": \"image_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes image id 391895 and returns the image file name COCO_val2014_000000391895.jpg\n",
    "# for example 522418 -> COCO_val2014_000000522418.jpg\n",
    "# 554625 -> COCO_val2014_000000554625.jpg\n",
    "def get_image_file_name(image_id):\n",
    "    return f\"COCO_val2014_{str(image_id).zfill(12)}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391895</td>\n",
       "      <td>COCO_val2014_000000391895.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>522418</td>\n",
       "      <td>COCO_val2014_000000522418.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184613</td>\n",
       "      <td>COCO_val2014_000000184613.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318219</td>\n",
       "      <td>COCO_val2014_000000318219.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>554625</td>\n",
       "      <td>COCO_val2014_000000554625.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40499</th>\n",
       "      <td>134574</td>\n",
       "      <td>COCO_val2014_000000134574.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40500</th>\n",
       "      <td>572233</td>\n",
       "      <td>COCO_val2014_000000572233.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40501</th>\n",
       "      <td>418825</td>\n",
       "      <td>COCO_val2014_000000418825.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40502</th>\n",
       "      <td>560744</td>\n",
       "      <td>COCO_val2014_000000560744.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40503</th>\n",
       "      <td>74478</td>\n",
       "      <td>COCO_val2014_000000074478.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40504 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                      file_name\n",
       "0        391895  COCO_val2014_000000391895.jpg\n",
       "1        522418  COCO_val2014_000000522418.jpg\n",
       "2        184613  COCO_val2014_000000184613.jpg\n",
       "3        318219  COCO_val2014_000000318219.jpg\n",
       "4        554625  COCO_val2014_000000554625.jpg\n",
       "...         ...                            ...\n",
       "40499    134574  COCO_val2014_000000134574.jpg\n",
       "40500    572233  COCO_val2014_000000572233.jpg\n",
       "40501    418825  COCO_val2014_000000418825.jpg\n",
       "40502    560744  COCO_val2014_000000560744.jpg\n",
       "40503     74478  COCO_val2014_000000074478.jpg\n",
       "\n",
       "[40504 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_cap_img_df[[\"image_id\", \"file_name\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laerdal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
